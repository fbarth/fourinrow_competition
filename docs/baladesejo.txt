Referências
A grande referência, com todo o sentido da palavra, Caio Emmanuel.
História do MCTS e AlphaGo Zero
Referência principal a MCTS
Referência mais didática a MCTS
Mais sobre MCTS e UCT
Implementação de MCTS para Connect Four regular, adaptados trechos como cálculo do UCT e nós da árvore
Ambiente competitivo Kaggle
Que algoritmo deve ser utilizado para desenvolver um agente jogador de Connect4 PopOut vencedor? Deve-se utilizar uma implementação de Min-Max com poda alpha-beta? Se sim, qual a profundidade que deverá ser utilizada para evitar processamentos superiores a 10 segundos por jogada? Qual a função de utilidade que deve ser utilizada?
O algoritmo usado foi MCTS. O agente desenvolvido utiliza um algoritmo de busca em uma árvore construída a partir do algoritmo de Monte Carlo, chamado Monte Carlo Tree Search (MCTS), que ganhou notoriedade depois de ter sido implementado no modelo AlphaGo Zero da Google que derrotou o então campeão mundial de Go em 2016 e um artigo para entender como isso foi feito pode ser lido nas referências ao fim.

O MCTS utiliza da inteligência do modelo Monte Carlo para selecionar o nó mais promissor em um árvore através de alguma regra que será explicada mais ao fim e, ao contrário de um algoritmo de busca cega uniforme, o modelo de Monte Carlo gera estados futuros aleatoriamente, dessa forma explorando caminhos que demorariam muito a serem verificados e testados em um problema de busca cega.

O algoritmo consiste fundamentalmente de quatro etapas:

Seleção: nessa etapa o algoritmo seleciona o nó mais promissor a partir da raiz da árvore

Expansão: nessa etapa o algoritmo expande o nó escolhido através de mais movimentos aleatórios

Simulação: nessa etapa o algoritmo simula o destino da partida a partir dos nós gerados pela expansão através de uma regra chamada policy que é o que adiciona "inteligência" ao algoritmo. Nessa implementação a policy usada será a Upper Confidence Trees (UCT), uma função de seleção baseada no número de nós visitados e o score do nó atual.

Atualização: através de um algoritmo de backpropagate, todos os nós no caminho entre o nó final e a raiz são atualizados com um novo valor para a policy

E repetimos isso até achar um nó vencedor.

O seu jogador faz uso de alguma base de conhecimento? Se sim, como ela é utilizada durante o processo de tomada de decisão?
Não.

Foi utilizada alguma função de utilidade não definida manualmente, por exemplo, alguma função de utilidade gerada a partir de um processo de aprendizagem de máquina supervisionado? Se sim, como é que foi o treinamento desta função de utilidade? Como foi feita a integração desta função de utilidade com o restante do código?
Não utiliza uma função de utilidade propriamente dita e sim uma policy, como explicado anteriormente.

Qual a sua expectativa com relação ao desempenho do seu agente? Você acredita que ele irá desempenhar bem na competição? Por que? Você executou testes contra outros jogadores? Qual foram os resultados?
Seria preciso criar outros agentes inteligentes para o jogo para poder validar. Pelos testes feitos, há uma eficácia de 98% contra um Random Player e 87% contra Negamax.

Quais foram as principais referências utilizadas para a implementação do seu jogador?
Podem ser vistas em referências.

Existem diferenças significativas entre um jogador de Connect4 e um jogador de Connect4 PopOut em termos de árvore de busca e função de avaliação? É possível utilizar o jogador implementado para o Connect4 PopOut em competições de Connect4 sem muitas modificações?
Não existem diferenças significativas além do comprimento da árvore de busca já que a árvore de busca para o Connect Four regular tem coeficiente de bifurcação limitado superiormente por 7 e o Connect Four PopOut é limitado superiormente por 13, as sete colunas regulares e mais seis opções de pop que é o máximo possível de colocar na linha mais de baixo sem ganhar a partida.